{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7393682,"sourceType":"datasetVersion","datasetId":4298390}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:16.694753Z","iopub.execute_input":"2024-01-21T15:52:16.695131Z","iopub.status.idle":"2024-01-21T15:52:16.705332Z","shell.execute_reply.started":"2024-01-21T15:52:16.695104Z","shell.execute_reply":"2024-01-21T15:52:16.703915Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/kaggle.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport os\n\n# Ensure kaggle.json is in the right location\nos.makedirs('/root/.kaggle', exist_ok=True)\n!cp /kaggle/input/dataset/kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json\n\n# Use Kaggle's API to download the Titanic competition data\n!kaggle competitions download -c titanic\n\n# Unzip the downloaded data\n!unzip -o titanic.zip -d /kaggle/working/titanic\n\n# Check the contents of the unzipped data\n!ls /kaggle/working/titanic","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-21T15:52:16.707757Z","iopub.execute_input":"2024-01-21T15:52:16.708124Z","iopub.status.idle":"2024-01-21T15:52:19.196483Z","shell.execute_reply.started":"2024-01-21T15:52:16.708092Z","shell.execute_reply":"2024-01-21T15:52:19.194788Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\nArchive:  titanic.zip\n  inflating: /kaggle/working/titanic/gender_submission.csv  \n  inflating: /kaggle/working/titanic/test.csv  \n  inflating: /kaggle/working/titanic/train.csv  \ngender_submission.csv  test.csv  train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntrain_csv = pd.read_csv('/kaggle/working/titanic/train.csv')\ntest_csv = pd.read_csv('/kaggle/working/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.198855Z","iopub.execute_input":"2024-01-21T15:52:19.199277Z","iopub.status.idle":"2024-01-21T15:52:19.216398Z","shell.execute_reply.started":"2024-01-21T15:52:19.199223Z","shell.execute_reply":"2024-01-21T15:52:19.215233Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_csv['Title'] = train_csv['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntest_csv['Title'] = test_csv['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# Define a mapping for title grouping\ntitle_mapping = {\n    \"Mr\": \"Mr\",\n    \"Miss\": \"Miss\",\n    \"Mrs\": \"Mrs\",\n    \"Master\": \"Master\",\n    \"Dr\": \"Professional\",\n    \"Rev\": \"Professional\",\n    \"Mlle\": \"Miss\",\n    \"Major\": \"Military\",\n    \"Col\": \"Military\",\n    \"Countess\": \"Nobility\",\n    \"Capt\": \"Military\",\n    \"Ms\": \"Miss\",\n    \"Sir\": \"Nobility\",\n    \"Lady\": \"Nobility\",\n    \"Mme\": \"Mrs\",\n    \"Don\": \"Nobility\",\n    \"Jonkheer\": \"Nobility\"\n}\n\n# Apply the mapping to the title column\ntrain_csv['Title'] = train_csv['Title'].map(title_mapping)\ntest_csv['Title'] = test_csv['Title'].map(title_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.218412Z","iopub.execute_input":"2024-01-21T15:52:19.218739Z","iopub.status.idle":"2024-01-21T15:52:19.231540Z","shell.execute_reply.started":"2024-01-21T15:52:19.218710Z","shell.execute_reply":"2024-01-21T15:52:19.229669Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_csv['Family_Size']=train_csv['SibSp']+train_csv['Parch']\ntest_csv['Family_Size']=test_csv['SibSp']+test_csv['Parch']\n\ntrain_csv['Age*Class']=train_csv['Age']*train_csv['Pclass']\ntest_csv['Age*Class']=test_csv['Age']*test_csv['Pclass']\n\ntrain_csv['Fare_Per_Person']=train_csv['Fare']/(train_csv['Family_Size']+1)\ntest_csv['Fare_Per_Person']=test_csv['Fare']/(test_csv['Family_Size']+1)\n\n# For the train dataset\ntrain_csv['Cabin'] = train_csv['Cabin'].fillna('Unknown')\ntrain_csv['Deck'] = train_csv['Cabin'].apply(lambda x: x[0] if x != 'Unknown' else 'Unknown')\n\n# For the test dataset\ntest_csv['Cabin'] = test_csv['Cabin'].fillna('Unknown')\ntest_csv['Deck'] = test_csv['Cabin'].apply(lambda x: x[0] if x != 'Unknown' else 'Unknown')\n\ntrain_csv.drop('Ticket', axis=1, inplace=True)\ntest_csv.drop('Ticket', axis=1, inplace=True)\n\ntrain_csv.drop('Name', axis=1, inplace=True)\ntest_csv.drop('Name', axis=1, inplace=True)\n\ntrain_csv.drop('Cabin', axis=1, inplace=True)\ntest_csv.drop('Cabin', axis=1, inplace=True)\n\ntrain_csv.drop('PassengerId', axis=1, inplace=True)\ntest_csv.drop('PassengerId', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.235036Z","iopub.execute_input":"2024-01-21T15:52:19.235494Z","iopub.status.idle":"2024-01-21T15:52:19.263772Z","shell.execute_reply.started":"2024-01-21T15:52:19.235457Z","shell.execute_reply":"2024-01-21T15:52:19.262463Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_csv.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.265289Z","iopub.execute_input":"2024-01-21T15:52:19.266860Z","iopub.status.idle":"2024-01-21T15:52:19.287610Z","shell.execute_reply.started":"2024-01-21T15:52:19.266793Z","shell.execute_reply":"2024-01-21T15:52:19.286103Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\n0         0       3    male  22.0      1      0   7.2500        S    Mr   \n1         1       1  female  38.0      1      0  71.2833        C   Mrs   \n2         1       3  female  26.0      0      0   7.9250        S  Miss   \n3         1       1  female  35.0      1      0  53.1000        S   Mrs   \n4         0       3    male  35.0      0      0   8.0500        S    Mr   \n\n   Family_Size  Age*Class  Fare_Per_Person     Deck  \n0            1       66.0          3.62500  Unknown  \n1            1       38.0         35.64165        C  \n2            0       78.0          7.92500  Unknown  \n3            1       35.0         26.55000        C  \n4            0      105.0          8.05000  Unknown  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Title</th>\n      <th>Family_Size</th>\n      <th>Age*Class</th>\n      <th>Fare_Per_Person</th>\n      <th>Deck</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>66.0</td>\n      <td>3.62500</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>Mrs</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>35.64165</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>Miss</td>\n      <td>0</td>\n      <td>78.0</td>\n      <td>7.92500</td>\n      <td>Unknown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>Mrs</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>26.55000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>Mr</td>\n      <td>0</td>\n      <td>105.0</td>\n      <td>8.05000</td>\n      <td>Unknown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_csv.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.289056Z","iopub.execute_input":"2024-01-21T15:52:19.289507Z","iopub.status.idle":"2024-01-21T15:52:19.302809Z","shell.execute_reply.started":"2024-01-21T15:52:19.289466Z","shell.execute_reply":"2024-01-21T15:52:19.300655Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Survived             int64\nPclass               int64\nSex                 object\nAge                float64\nSibSp                int64\nParch                int64\nFare               float64\nEmbarked            object\nTitle               object\nFamily_Size          int64\nAge*Class          float64\nFare_Per_Person    float64\nDeck                object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"categorical_columns = ['Sex', 'Embarked', 'Title', 'Deck']\nnumerical_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Family_Size', 'Age*Class', 'Fare_Per_Person']","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.304580Z","iopub.execute_input":"2024-01-21T15:52:19.305033Z","iopub.status.idle":"2024-01-21T15:52:19.314201Z","shell.execute_reply.started":"2024-01-21T15:52:19.305000Z","shell.execute_reply":"2024-01-21T15:52:19.312717Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef process_categorical_variables(df, categorical_columns, missing_values_strategy='most_frequent'):\n    \"\"\"\n    Process categorical variables in a DataFrame.\n    \n    Args:\n    df (pd.DataFrame): The DataFrame to process.\n    categorical_columns (list of str): List of column names in df that are categorical.\n    missing_values_strategy (str): Strategy for imputing missing values in categorical columns.\n                                   Options: 'most_frequent', 'constant' (replaces with 'Unknown')\n    \n    Returns:\n    pd.DataFrame: A DataFrame with processed categorical variables.\n    \"\"\"\n    df_processed = df.copy()\n    \n    # Impute missing values in categorical columns\n    if missing_values_strategy == 'constant':\n        filler = 'Unknown'\n    else:  # Default to 'most_frequent'\n        filler = 'most_frequent'\n    \n    cat_imputer = SimpleImputer(strategy=missing_values_strategy, fill_value=filler)\n    df_processed[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n    \n    # Apply one-hot encoding\n    one_hot = OneHotEncoder(handle_unknown='ignore', sparse=False)\n    encoded_vars = pd.DataFrame(one_hot.fit_transform(df_processed[categorical_columns]))\n    \n    # One-hot encoding removes index; put it back\n    encoded_vars.index = df_processed.index\n    \n    # Add column names to encoded vars\n    encoded_vars.columns = one_hot.get_feature_names_out(categorical_columns)\n    \n    # Drop original categorical columns and concatenate encoded variables\n    df_processed = pd.concat([df_processed.drop(categorical_columns, axis=1), encoded_vars], axis=1)\n    \n    return df_processed\n\n# Example usage:\n# df_processed = process_categorical_variables(df, ['cat_col1', 'cat_col2'], missing_values_strategy='constant')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.316064Z","iopub.execute_input":"2024-01-21T15:52:19.316415Z","iopub.status.idle":"2024-01-21T15:52:19.328957Z","shell.execute_reply.started":"2024-01-21T15:52:19.316388Z","shell.execute_reply":"2024-01-21T15:52:19.328097Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"process_categorical_variables(train_csv, categorical_columns, 'constant')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.330444Z","iopub.execute_input":"2024-01-21T15:52:19.330734Z","iopub.status.idle":"2024-01-21T15:52:19.381948Z","shell.execute_reply.started":"2024-01-21T15:52:19.330712Z","shell.execute_reply":"2024-01-21T15:52:19.381108Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"     Survived  Pclass   Age  SibSp  Parch     Fare  Family_Size  Age*Class  \\\n0           0       3  22.0      1      0   7.2500            1       66.0   \n1           1       1  38.0      1      0  71.2833            1       38.0   \n2           1       3  26.0      0      0   7.9250            0       78.0   \n3           1       1  35.0      1      0  53.1000            1       35.0   \n4           0       3  35.0      0      0   8.0500            0      105.0   \n..        ...     ...   ...    ...    ...      ...          ...        ...   \n886         0       2  27.0      0      0  13.0000            0       54.0   \n887         1       1  19.0      0      0  30.0000            0       19.0   \n888         0       3   NaN      1      2  23.4500            3        NaN   \n889         1       1  26.0      0      0  30.0000            0       26.0   \n890         0       3  32.0      0      0   7.7500            0       96.0   \n\n     Fare_Per_Person  Sex_female  ...  Title_Professional  Deck_A  Deck_B  \\\n0            3.62500         0.0  ...                 0.0     0.0     0.0   \n1           35.64165         1.0  ...                 0.0     0.0     0.0   \n2            7.92500         1.0  ...                 0.0     0.0     0.0   \n3           26.55000         1.0  ...                 0.0     0.0     0.0   \n4            8.05000         0.0  ...                 0.0     0.0     0.0   \n..               ...         ...  ...                 ...     ...     ...   \n886         13.00000         0.0  ...                 1.0     0.0     0.0   \n887         30.00000         1.0  ...                 0.0     0.0     1.0   \n888          5.86250         1.0  ...                 0.0     0.0     0.0   \n889         30.00000         0.0  ...                 0.0     0.0     0.0   \n890          7.75000         0.0  ...                 0.0     0.0     0.0   \n\n     Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_Unknown  \n0       0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n1       1.0     0.0     0.0     0.0     0.0     0.0           0.0  \n2       0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n3       1.0     0.0     0.0     0.0     0.0     0.0           0.0  \n4       0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n..      ...     ...     ...     ...     ...     ...           ...  \n886     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n887     0.0     0.0     0.0     0.0     0.0     0.0           0.0  \n888     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n889     1.0     0.0     0.0     0.0     0.0     0.0           0.0  \n890     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n\n[891 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Family_Size</th>\n      <th>Age*Class</th>\n      <th>Fare_Per_Person</th>\n      <th>Sex_female</th>\n      <th>...</th>\n      <th>Title_Professional</th>\n      <th>Deck_A</th>\n      <th>Deck_B</th>\n      <th>Deck_C</th>\n      <th>Deck_D</th>\n      <th>Deck_E</th>\n      <th>Deck_F</th>\n      <th>Deck_G</th>\n      <th>Deck_T</th>\n      <th>Deck_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>1</td>\n      <td>66.0</td>\n      <td>3.62500</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>35.64165</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>78.0</td>\n      <td>7.92500</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>26.55000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>105.0</td>\n      <td>8.05000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>0</td>\n      <td>2</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>0</td>\n      <td>54.0</td>\n      <td>13.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>1</td>\n      <td>1</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0</td>\n      <td>19.0</td>\n      <td>30.00000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>5.86250</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>1</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>30.00000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>0</td>\n      <td>3</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>0</td>\n      <td>96.0</td>\n      <td>7.75000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\ndef process_numerical_variables(df, numerical_columns, missing_values_strategy='mean', scale_data=False, scaling_method='standard'):\n    \"\"\"\n    Process numerical variables in a DataFrame.\n    \n    Args:\n    df (pd.DataFrame): The DataFrame to process.\n    numerical_columns (list of str): List of column names in df that are numerical.\n    missing_values_strategy (str): Strategy for imputing missing values in numerical columns.\n                                   Options: 'mean', 'median', 'constant'.\n    scale_data (bool): Whether to scale numerical data.\n    scaling_method (str): Scaling method to use if scale_data is True.\n                          Options: 'standard' for StandardScaler, 'minmax' for MinMaxScaler.\n    \n    Returns:\n    pd.DataFrame: A DataFrame with processed numerical variables.\n    \"\"\"\n    df_processed = df.copy()\n    \n    # Impute missing values in numerical columns\n    if missing_values_strategy not in ['mean', 'median', 'constant']:\n        raise ValueError(\"Invalid missing_values_strategy. Choose 'mean', 'median', or 'constant'.\")\n    \n    if missing_values_strategy =='constant':\n        num_imputer = SimpleImputer(strategy=missing_values_strategy,  fill_value=-1)\n        df_processed[numerical_columns] = num_imputer.fit_transform(df[numerical_columns])\n    \n    else:\n        num_imputer = SimpleImputer(strategy=missing_values_strategy)\n        df_processed[numerical_columns] = num_imputer.fit_transform(df[numerical_columns])\n\n    # Scale data if required\n    if scale_data:\n        if scaling_method == 'standard':\n            scaler = StandardScaler()\n        elif scaling_method == 'minmax':\n            scaler = MinMaxScaler()\n        else:\n            raise ValueError(\"Invalid scaling_method. Choose 'standard' or 'minmax'.\")\n        \n        df_processed[numerical_columns] = scaler.fit_transform(df_processed[numerical_columns])\n\n    return df_processed\n\n# Example usage:\n# df_processed = process_numerical_variables(df, ['num_col1', 'num_col2'], missing_values_strategy='median', scale_data=True, scaling_method='minmax')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.386497Z","iopub.execute_input":"2024-01-21T15:52:19.387221Z","iopub.status.idle":"2024-01-21T15:52:19.395841Z","shell.execute_reply.started":"2024-01-21T15:52:19.387194Z","shell.execute_reply":"2024-01-21T15:52:19.394948Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_df_cat = process_categorical_variables(train_csv, categorical_columns, 'constant')\ntrain_df_processed = process_numerical_variables(train_df_cat, numerical_columns, missing_values_strategy='constant')\n\n\ntest_df_cat = process_categorical_variables(test_csv, categorical_columns, 'constant')\ntest_df_processed = process_numerical_variables(test_df_cat, numerical_columns, missing_values_strategy='constant')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.397069Z","iopub.execute_input":"2024-01-21T15:52:19.398038Z","iopub.status.idle":"2024-01-21T15:52:19.445576Z","shell.execute_reply.started":"2024-01-21T15:52:19.398007Z","shell.execute_reply":"2024-01-21T15:52:19.444467Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df_processed.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.447090Z","iopub.execute_input":"2024-01-21T15:52:19.447464Z","iopub.status.idle":"2024-01-21T15:52:19.476877Z","shell.execute_reply.started":"2024-01-21T15:52:19.447432Z","shell.execute_reply":"2024-01-21T15:52:19.475716Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   Survived  Pclass   Age  SibSp  Parch     Fare  Family_Size  Age*Class  \\\n0         0     3.0  22.0    1.0    0.0   7.2500          1.0       66.0   \n1         1     1.0  38.0    1.0    0.0  71.2833          1.0       38.0   \n2         1     3.0  26.0    0.0    0.0   7.9250          0.0       78.0   \n3         1     1.0  35.0    1.0    0.0  53.1000          1.0       35.0   \n4         0     3.0  35.0    0.0    0.0   8.0500          0.0      105.0   \n\n   Fare_Per_Person  Sex_female  ...  Title_Professional  Deck_A  Deck_B  \\\n0          3.62500         0.0  ...                 0.0     0.0     0.0   \n1         35.64165         1.0  ...                 0.0     0.0     0.0   \n2          7.92500         1.0  ...                 0.0     0.0     0.0   \n3         26.55000         1.0  ...                 0.0     0.0     0.0   \n4          8.05000         0.0  ...                 0.0     0.0     0.0   \n\n   Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T  Deck_Unknown  \n0     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n1     1.0     0.0     0.0     0.0     0.0     0.0           0.0  \n2     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n3     1.0     0.0     0.0     0.0     0.0     0.0           0.0  \n4     0.0     0.0     0.0     0.0     0.0     0.0           1.0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Family_Size</th>\n      <th>Age*Class</th>\n      <th>Fare_Per_Person</th>\n      <th>Sex_female</th>\n      <th>...</th>\n      <th>Title_Professional</th>\n      <th>Deck_A</th>\n      <th>Deck_B</th>\n      <th>Deck_C</th>\n      <th>Deck_D</th>\n      <th>Deck_E</th>\n      <th>Deck_F</th>\n      <th>Deck_G</th>\n      <th>Deck_T</th>\n      <th>Deck_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3.0</td>\n      <td>22.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.2500</td>\n      <td>1.0</td>\n      <td>66.0</td>\n      <td>3.62500</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>38.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>71.2833</td>\n      <td>1.0</td>\n      <td>38.0</td>\n      <td>35.64165</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3.0</td>\n      <td>26.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.9250</td>\n      <td>0.0</td>\n      <td>78.0</td>\n      <td>7.92500</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>35.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>53.1000</td>\n      <td>1.0</td>\n      <td>35.0</td>\n      <td>26.55000</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3.0</td>\n      <td>35.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0500</td>\n      <td>0.0</td>\n      <td>105.0</td>\n      <td>8.05000</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Separate target variable\nX = train_df_processed.drop('Survived', axis=1)\ny = train_df_processed['Survived']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.478406Z","iopub.execute_input":"2024-01-21T15:52:19.478728Z","iopub.status.idle":"2024-01-21T15:52:19.491017Z","shell.execute_reply.started":"2024-01-21T15:52:19.478703Z","shell.execute_reply":"2024-01-21T15:52:19.489631Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Initialize the Random Forest Classifier\n# n_estimators is the number of trees in the forest\n# max_depth is the maximum depth of the trees\n# random_state is used for reproducibility of your results\nrf_clf = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n\n# Fit the model on the training data\nrf_clf.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = rf_clf.predict(X_test)\n\n# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\n\n# Generate a classification report\nreport = classification_report(y_test, y_pred)\n\n# Generate a confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Print the results\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Classification Report:\")\nprint(report)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.492474Z","iopub.execute_input":"2024-01-21T15:52:19.492810Z","iopub.status.idle":"2024-01-21T15:52:19.700994Z","shell.execute_reply.started":"2024-01-21T15:52:19.492778Z","shell.execute_reply":"2024-01-21T15:52:19.699788Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Accuracy: 0.8268156424581006\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.86      0.85       105\n           1       0.79      0.78      0.79        74\n\n    accuracy                           0.83       179\n   macro avg       0.82      0.82      0.82       179\nweighted avg       0.83      0.83      0.83       179\n\nConfusion Matrix:\n[[90 15]\n [16 58]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **1. Grid Search**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'n_estimators': [100, 200],  # Number of trees in the forest\n    'max_depth': [None, 10],  # Maximum depth of the tree\n    'min_samples_split': [2, 5],  # Minimum number of samples required to split a node\n    'min_samples_leaf': [1, 2],  # Minimum number of samples required at each leaf node\n    'bootstrap': [True, False]  # Method of selecting samples for training each tree\n}\n\n\ngrid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n                           param_grid=param_grid, \n                           cv=5,  # Number of cross-validation folds\n                           n_jobs=-1,  # Use all CPU cores\n                           verbose=2,  # Higher number gives more information about the process\n                           scoring='accuracy'  # Can choose other metrics like 'f1', 'precision', 'recall'\n                           )\n\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:19.702916Z","iopub.execute_input":"2024-01-21T15:52:19.703340Z","iopub.status.idle":"2024-01-21T15:52:35.783938Z","shell.execute_reply.started":"2024-01-21T15:52:19.703303Z","shell.execute_reply":"2024-01-21T15:52:35.782991Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 32 candidates, totalling 160 fits\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={'bootstrap': [True, False], 'max_depth': [None, 10],\n                         'min_samples_leaf': [1, 2],\n                         'min_samples_split': [2, 5],\n                         'n_estimators': [100, 200]},\n             scoring='accuracy', verbose=2)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [None, 10],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 5],\n                         &#x27;n_estimators&#x27;: [100, 200]},\n             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n             param_grid={&#x27;bootstrap&#x27;: [True, False], &#x27;max_depth&#x27;: [None, 10],\n                         &#x27;min_samples_leaf&#x27;: [1, 2],\n                         &#x27;min_samples_split&#x27;: [2, 5],\n                         &#x27;n_estimators&#x27;: [100, 200]},\n             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Get the best parameters and the best score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\n\nprint(f\"Best parameters: {best_params}\")\nprint(f\"Best cross-validation score: {best_score}\")\n\n# Get the best estimator\nbest_model = grid_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:35.785258Z","iopub.execute_input":"2024-01-21T15:52:35.786482Z","iopub.status.idle":"2024-01-21T15:52:35.792628Z","shell.execute_reply.started":"2024-01-21T15:52:35.786442Z","shell.execute_reply":"2024-01-21T15:52:35.791277Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Best parameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\nBest cross-validation score: 0.8370530877573131\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict on the test data using the best model\ny_pred = best_model.predict(X_test)\n\n# Calculate the accuracy or other performance metrics on the test set\ntest_accuracy = accuracy_score(y_test, y_pred)\ntest_classification_report = classification_report(y_test, y_pred)\ntest_confusion_matrix = confusion_matrix(y_test, y_pred)\n\n# Output the performance\nprint(f\"Test Set Accuracy: {test_accuracy}\")\nprint(\"Test Set Classification Report:\")\nprint(test_classification_report)\nprint(\"Test Set Confusion Matrix:\")\nprint(test_confusion_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:35.793945Z","iopub.execute_input":"2024-01-21T15:52:35.794229Z","iopub.status.idle":"2024-01-21T15:52:35.829547Z","shell.execute_reply.started":"2024-01-21T15:52:35.794205Z","shell.execute_reply":"2024-01-21T15:52:35.828509Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Test Set Accuracy: 0.8435754189944135\nTest Set Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       105\n           1       0.85      0.76      0.80        74\n\n    accuracy                           0.84       179\n   macro avg       0.84      0.83      0.84       179\nweighted avg       0.84      0.84      0.84       179\n\nTest Set Confusion Matrix:\n[[95 10]\n [18 56]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **2. Random Search**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nfrom scipy.stats import randint, uniform\n\nparam_dist = {\n    'n_estimators': randint(100, 500),  # Uniformly distributed integer random values within the given range\n    'max_depth': [None] + list(range(5, 51, 5)),  # None plus a range from 5 to 50 in steps of 5\n    'min_samples_split': randint(2, 20),  # Same as 'n_estimators'\n    'min_samples_leaf': randint(1, 10),\n    'bootstrap': [True, False],  # Discrete, non-numerical parameters still need to be a list of options\n    'max_features': uniform(0.1, 0.9)  # Float values within a range, assuming max_features is used as a float\n}\n\nrandom_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), \n                                   param_distributions=param_dist, \n                                   n_iter=50,  # Number of parameter settings that are sampled\n                                   cv=5,  # Number of cross-validation folds\n                                   n_jobs=-1,  # Use all CPU cores\n                                   verbose=0,  # Higher number gives more information about the process\n                                   random_state=42,  # For reproducible results\n                                   scoring='accuracy'  # Can choose other metrics like 'f1', 'precision', 'recall'\n                                   )\n\nrandom_search.fit(X_train, y_train)\n\nbest_params = random_search.best_params_\nbest_score = random_search.best_score_\n\nprint(f\"Best parameters: {best_params}\")\nprint(f\"Best cross-validation score: {best_score}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:52:35.831318Z","iopub.execute_input":"2024-01-21T15:52:35.831668Z","iopub.status.idle":"2024-01-21T15:53:27.238037Z","shell.execute_reply.started":"2024-01-21T15:52:35.831638Z","shell.execute_reply":"2024-01-21T15:53:27.235831Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Best parameters: {'bootstrap': False, 'max_depth': 40, 'max_features': 0.14180537144799796, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 120}\nBest cross-validation score: 0.8356446370530879\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the best parameters and the best score\nbest_params = random_search.best_params_\nbest_score = random_search.best_score_\n\nprint(f\"Best parameters: {best_params}\")\nprint(f\"Best cross-validation score: {best_score}\")\n\n# Get the best estimator\nbest_model = random_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:53:27.240346Z","iopub.execute_input":"2024-01-21T15:53:27.240741Z","iopub.status.idle":"2024-01-21T15:53:27.247856Z","shell.execute_reply.started":"2024-01-21T15:53:27.240711Z","shell.execute_reply":"2024-01-21T15:53:27.246743Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Best parameters: {'bootstrap': False, 'max_depth': 40, 'max_features': 0.14180537144799796, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 120}\nBest cross-validation score: 0.8356446370530879\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict on the test data using the best model\ny_pred = best_model.predict(X_test)\n\n# Calculate the accuracy or other performance metrics on the test set\ntest_accuracy = accuracy_score(y_test, y_pred)\ntest_classification_report = classification_report(y_test, y_pred)\ntest_confusion_matrix = confusion_matrix(y_test, y_pred)\n\n# Output the performance\nprint(f\"Test Set Accuracy: {test_accuracy}\")\nprint(\"Test Set Classification Report:\")\nprint(test_classification_report)\nprint(\"Test Set Confusion Matrix:\")\nprint(test_confusion_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T15:53:27.249060Z","iopub.execute_input":"2024-01-21T15:53:27.250536Z","iopub.status.idle":"2024-01-21T15:53:27.277384Z","shell.execute_reply.started":"2024-01-21T15:53:27.250457Z","shell.execute_reply":"2024-01-21T15:53:27.276413Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Test Set Accuracy: 0.8379888268156425\nTest Set Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.84      0.90      0.87       105\n           1       0.84      0.76      0.79        74\n\n    accuracy                           0.84       179\n   macro avg       0.84      0.83      0.83       179\nweighted avg       0.84      0.84      0.84       179\n\nTest Set Confusion Matrix:\n[[94 11]\n [18 56]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **3. Bayesian Search**","metadata":{}},{"cell_type":"code","source":"import optuna\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport logging\n\n# Set the logging level to WARN to reduce output\n# This will display only warnings and errors\nlogging.getLogger('optuna').setLevel(logging.WARNING)\n\ndef objective(trial):\n    # Hyperparameters to tune\n    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n    max_depth = trial.suggest_int('max_depth', 5, 50)\n    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n    \n    # Initialize the classifier with current hyperparameters\n    clf = RandomForestClassifier(\n        n_estimators=n_estimators, \n        max_depth=max_depth, \n        min_samples_split=min_samples_split, \n        min_samples_leaf=min_samples_leaf, \n        bootstrap=bootstrap,\n        random_state=42\n    )\n    \n    # Perform cross-validation\n    score = cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=5, scoring='accuracy').mean()\n    return score\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)\n\n# Best hyperparameters\nbest_params = study.best_trial.params\nprint(\"Best hyperparameters:\", best_params)\n\n# Train the best model\nbest_model = RandomForestClassifier(**best_params, random_state=42)\nbest_model.fit(X_train, y_train)\n\n# Evaluate on the test set\ny_pred = best_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Set Accuracy: {accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:00:33.880155Z","iopub.execute_input":"2024-01-21T16:00:33.880492Z","iopub.status.idle":"2024-01-21T16:01:58.334203Z","shell.execute_reply.started":"2024-01-21T16:00:33.880468Z","shell.execute_reply":"2024-01-21T16:01:58.332367Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Best hyperparameters: {'n_estimators': 254, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 6, 'bootstrap': False}\nTest Set Accuracy: 0.8547486033519553\n","output_type":"stream"}]},{"cell_type":"code","source":"X_final = test_df_processed\n\n# Assuming X_train_encoded is the training data after one-hot encoding\n# and X_final is the new data after one-hot encoding\n\n# Get the list of columns from the training set\ntrain_cols = X_train.columns\n\n# Identify the missing columns in the test set and fill them with 0s\nfor col in train_cols:\n    if col not in X_final.columns:\n        X_final[col] = 0\n\n# Reorder the columns of X_final to match the order of X_train columns\nX_final_aligned = X_final[train_cols]\n\n# Now X_final_aligned has the same column structure as X_train_encoded\n\n\nbest_model.predict(X_final_aligned)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T17:02:42.185634Z","iopub.execute_input":"2024-01-21T17:02:42.185988Z","iopub.status.idle":"2024-01-21T17:02:42.226305Z","shell.execute_reply.started":"2024-01-21T17:02:42.185959Z","shell.execute_reply":"2024-01-21T17:02:42.225275Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n       0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"X_final_init = pd.read_csv('/kaggle/working/titanic/test.csv')\n\nX_final_init.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T17:05:30.641529Z","iopub.execute_input":"2024-01-21T17:05:30.641862Z","iopub.status.idle":"2024-01-21T17:05:30.661076Z","shell.execute_reply.started":"2024-01-21T17:05:30.641838Z","shell.execute_reply":"2024-01-21T17:05:30.659682Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output = X_final_init[['PassengerId']]\n\noutput['Survived'] = best_model.predict(X_final_aligned)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T17:06:49.490218Z","iopub.execute_input":"2024-01-21T17:06:49.490884Z","iopub.status.idle":"2024-01-21T17:06:49.524303Z","shell.execute_reply.started":"2024-01-21T17:06:49.490859Z","shell.execute_reply":"2024-01-21T17:06:49.522588Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/1711658204.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  output['Survived'] = best_model.predict(X_final_aligned)\n","output_type":"stream"}]},{"cell_type":"code","source":"output.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T17:11:35.700569Z","iopub.execute_input":"2024-01-21T17:11:35.700891Z","iopub.status.idle":"2024-01-21T17:11:35.709801Z","shell.execute_reply.started":"2024-01-21T17:11:35.700869Z","shell.execute_reply":"2024-01-21T17:11:35.708963Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}